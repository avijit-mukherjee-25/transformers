{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMjX7GLK4iDZpnXzHXN+Ze5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avijit-mukherjee-25/transformers/blob/main/Transformer_to_classify_MNIST_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bak5ojInvENn"
      },
      "outputs": [],
      "source": [
        "# install libraries\n",
        "!pip install transformers torch numpy datasets evaluate matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import dependencies"
      ],
      "metadata": {
        "id": "hBG4ImZsxDlt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "6M5kGDZ3vepl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "VnEJti51xGLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get global hyper params"
      ],
      "metadata": {
        "id": "uiyKhJcKxn4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "learning_rate = 1e-4\n",
        "num_epochs = 10\n",
        "num_heads = 4\n",
        "num_layers = 4\n",
        "d_model = 512"
      ],
      "metadata": {
        "id": "3-CAY64yxoqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Data"
      ],
      "metadata": {
        "id": "5Rn3Km3ZxLHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.MNIST(root=\"./datasets/\", train=True, download=True, transform=ToTensor())\n",
        "test_dataset = datasets.MNIST(root=\"./datasets/\", train=False, download=True, transform=ToTensor())"
      ],
      "metadata": {
        "id": "gX_JTCl9xJsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, test_dataset"
      ],
      "metadata": {
        "id": "kxx2GnkGxPzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nornalize the data\n",
        "imgs = torch.stack([img for img, _ in train_dataset], dim=0)\n",
        "print (imgs.shape)\n",
        "mean = imgs.view(1, -1).mean(dim=1)\n",
        "std = imgs.view(1, -1).std(dim=1)\n",
        "print (mean, std)"
      ],
      "metadata": {
        "id": "K51HJbgRxSL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transform data\n",
        "mnist_transforms = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=mean, std=std)])"
      ],
      "metadata": {
        "id": "10pfxUtNxU1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.MNIST(root=\"./datasets/\", train=True, download=False, transform=mnist_transforms)\n",
        "test_dataset = datasets.MNIST(root=\"./datasets/\", train=False, download=False, transform=mnist_transforms)\n",
        "train_dataset, test_dataset"
      ],
      "metadata": {
        "id": "qi_1FoCJxW5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pick a random image and plot\n",
        "random_idx = np.random.randint(0, len(train_dataset))\n",
        "print (random_idx)\n",
        "\n",
        "img, label = train_dataset[random_idx]\n",
        "print (img.shape)\n",
        "plt.imshow(img.squeeze(), cmap='gray')\n",
        "print (label)"
      ],
      "metadata": {
        "id": "MaN0f-iAxYvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Let's see no of batches that we have now with the current batch-size\n",
        "print (len(train_dataloader), len(test_dataloader))\n",
        "print (len(train_dataset), len(train_dataloader.dataset))"
      ],
      "metadata": {
        "id": "_LyO7p89xa-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define train and test functions"
      ],
      "metadata": {
        "id": "UsSKvLAzyPij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "id": "Lykhd6py8DIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate"
      ],
      "metadata": {
        "id": "w7d-YH9axdvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, loss_fn, train_dataloader):\n",
        "    train_loss = 0.0\n",
        "    model.train()\n",
        "    metric = evaluate.load(\"accuracy\")\n",
        "    for step, (X, y) in enumerate(train_dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        logits = model(X)\n",
        "        loss = loss_fn(logits, y)\n",
        "        train_loss += loss.item()\n",
        "        metric.add_batch(predictions=logits.argmax(dim=1), references=y)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if step%1000==0:\n",
        "            print (f'training loss at {step} is {train_loss}')\n",
        "    train_accuracy = metric.compute()\n",
        "    return train_loss, train_accuracy"
      ],
      "metadata": {
        "id": "tUn_CyOzySzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def eval(model, test_dataloader):\n",
        "    model.eval()\n",
        "    metric = evaluate.load(\"accuracy\")\n",
        "    test_loss = 0.0\n",
        "    for _, (X, y) in enumerate(test_dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        logits = model(X)\n",
        "        loss = loss_fn(logits, y)\n",
        "        test_loss += loss.item()\n",
        "        metric.add_batch(predictions=logits.argmax(dim=1), references=y)\n",
        "    test_accuracy = metric.compute()\n",
        "    model.train()\n",
        "    return test_loss, test_accuracy"
      ],
      "metadata": {
        "id": "n1KdwqFtyYD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LeNet"
      ],
      "metadata": {
        "id": "sQuI2fkTybsj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the model\n",
        "class LeNet(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        # 1 input image channel (black & white), 6 output channels, 5x5 square convolution\n",
        "        # kernel\n",
        "        self.feature = nn.Sequential(\n",
        "            #1\n",
        "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2),   # 28*28->32*32-->28*28\n",
        "            nn.Tanh(),\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2),  # 14*14\n",
        "\n",
        "            #2\n",
        "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),  # 10*10\n",
        "            nn.Tanh(),\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2),  # 5*5\n",
        "\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features=16*5*5, out_features=120),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(in_features=120, out_features=84),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(in_features=84, out_features=10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.classifier(self.feature(x))\n",
        "\n",
        "LeNet_model = LeNet()\n",
        "LeNet_model.to(device)"
      ],
      "metadata": {
        "id": "8fHuYJgZyaCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparams\n",
        "from torch.optim import AdamW\n",
        "optimizer = AdamW(LeNet_model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "KknwGg6Xye-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    print (f'Epoch: {epoch}')\n",
        "    train_loss, train_accuracy = train(LeNet_model, optimizer, loss_fn, train_dataloader)\n",
        "    print (f'train loss at epoch {epoch} is {train_loss}; train accuracy is {train_accuracy}')\n",
        "    test_loss, test_accuracy = eval(LeNet_model, test_dataloader)\n",
        "    print (f'test loss at epoch {epoch} is {test_loss}; test accuracy is {test_accuracy}')"
      ],
      "metadata": {
        "id": "JBkVH0Qiyl46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ViT"
      ],
      "metadata": {
        "id": "UlErhUo98VTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the model\n",
        "class ViT(nn.Module):\n",
        "\n",
        "    def __init__(self, num_heads, num_layers, d_model):\n",
        "        super(ViT, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            #1 conv\n",
        "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2),   # 28*28->32*32-->28*28\n",
        "            nn.Tanh(),\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2),  # batch_size*out_channels*14*14\n",
        "\n",
        "            #2 conv\n",
        "            nn.Conv2d(in_channels=6, out_channels=d_model, kernel_size=5, stride=1),  # 10*10\n",
        "            nn.Tanh(),\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2),  # batch_size*out_channels*5*5\n",
        "        )\n",
        "        self.transformer_encoder_layer = nn.TransformerEncoderLayer(\n",
        "               d_model=d_model, nhead=num_heads,\n",
        "               dim_feedforward=int(d_model * 4),\n",
        "               dropout=0.1,\n",
        "               batch_first = True\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(\n",
        "                   encoder_layer=self.transformer_encoder_layer,\n",
        "                   num_layers=num_layers\n",
        "        )\n",
        "        self.linear = nn.Linear(d_model, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x) # --> batch_size*d_model*5*5\n",
        "        x = x.flatten(start_dim=2).permute(0,2,1) # --> batch_size*seq*d_model\n",
        "\n",
        "        _batch_size = x.shape[0]\n",
        "        cls_token = nn.Parameter(torch.randn(1, 1, d_model)).to(device)\n",
        "        cls_tokens = cls_token.expand(_batch_size, -1, -1)\n",
        "        x = torch.cat((cls_tokens, x), dim=1)\n",
        "        _batch_size, _seq_len, _ = x.shape\n",
        "        x += nn.Parameter(torch.randn(_batch_size, _seq_len, d_model)).to(device)\n",
        "\n",
        "        x = self.transformer_encoder(x) # --> batch_size*(seq+1)*d_model\n",
        "\n",
        "        out = self.linear(x[:,0,:])\n",
        "\n",
        "        return out\n",
        "\n",
        "ViT_model = ViT(num_heads, num_layers, d_model)\n",
        "ViT_model.to(device)"
      ],
      "metadata": {
        "id": "qOwmpIJKyvYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "optimizer = AdamW(ViT_model.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "id": "xb-r55hR8agN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    print (f'Epoch: {epoch}')\n",
        "    train_loss, train_accuracy = train(ViT_model, optimizer, loss_fn, train_dataloader)\n",
        "    print (f'train loss at epoch {epoch} is {train_loss}; train accuracy is {train_accuracy}')\n",
        "    test_loss, test_accuracy = eval(ViT_model, test_dataloader)\n",
        "    print (f'test loss at epoch {epoch} is {test_loss}; test accuracy is {test_accuracy}')"
      ],
      "metadata": {
        "id": "qlgnPfJ18eMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gHVQdPDv8gZd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}